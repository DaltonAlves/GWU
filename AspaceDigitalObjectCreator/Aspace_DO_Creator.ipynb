{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnkfonCGpKJM"
   },
   "source": [
    "# In the cell below, add the full path to your CSV spreadsheet.\n",
    "\n",
    "Also, if there are any additional types of preservation URLs, add a unique part of each URL to the list called \"preservation URLS_have\". The list should be formatted like ['a','b','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Z7Da_5h2pKJU"
   },
   "outputs": [],
   "source": [
    "donesheet = '' #put file path here!\n",
    "preservation_URLS_have = ['preservation-storage1','gwspec-digcol1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3-XclJrLpKJV"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOKR8GN6pKJW"
   },
   "source": [
    "# In the cell below, add your username, password, and API host (GW Dev or Prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMXjA4kxpKJY",
    "outputId": "dfbf7d14-5ae5-4efa-923e-554f6a2cde66"
   },
   "outputs": [],
   "source": [
    "USER = ''\n",
    "PASS = ''\n",
    "HOST = ''\n",
    "def aspace_auth(host, username, password):\n",
    "    auth = requests.post(HOST + '/users/' + username + '/login',\n",
    "                        params={'password' : password})\n",
    "    if auth.status_code == 200:\n",
    "        token = auth.json()['session']\n",
    "        headers = {'X-ArchivesSpace-Session': token}\n",
    "        return(headers)\n",
    "    else:\n",
    "        return(False)\n",
    "\n",
    "headers = aspace_auth(HOST, USER, PASS)\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odw0OkfApKJZ"
   },
   "source": [
    "# Don't edit anything below. To update ArchivesSpace, run the below cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Aoh-4VzpKJZ",
    "outputId": "b9e2198a-9f44-4c9b-d413-3e5d65443eb2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits): #this function is used for faux codes\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "def extract_key_value_pairs(csv_file): #this function is used to create key value pairs from csv\n",
    "    key_value_pairs = []\n",
    "\n",
    "    with open(csv_file, 'r', encoding='utf-8-sig') as file:\n",
    "        reader = csv.reader(file)\n",
    "        headers = next(reader)  # Extract the header row\n",
    "        \n",
    "        for row in reader:\n",
    "            key_value = {header: value for header, value in zip(headers, row)}\n",
    "            key_value_pairs.append(key_value)\n",
    "    \n",
    "    return key_value_pairs\n",
    "\n",
    "csv_file = donesheet\n",
    "inputdata = extract_key_value_pairs(csv_file)\n",
    "\n",
    "for item in inputdata:\n",
    "    skipitem = False #flag\n",
    "\n",
    "    #report to operator\n",
    "    print('Starting: ' + item['file_uri'])\n",
    "    print('Archival object: ' + item['archival_object'])\n",
    "\n",
    "    #get the archival object ID\n",
    "    if re.search('.+archival_object_(\\d+)$', item['archival_object']):\n",
    "        ao_id = re.search('.+archival_object_(\\d+)$', item['archival_object']).group(1)\n",
    "    else:\n",
    "        raise Exception('It looks like we found an archival object whose link isn\\'t well formatted: ' + str(item['archival_object']))\n",
    "\n",
    "    #create the file_version dictionary to add to digital object\n",
    "    file_uri = item['file_uri']\n",
    "    if item['publish_link'] == \"TRUE\":\n",
    "        publish = True\n",
    "    elif item['publish_link'] == \"FALSE\":\n",
    "        publish = False\n",
    "    else:\n",
    "        print('ERROR: Please go back and check your publish column. Found a value other than True/False.')\n",
    "        break\n",
    "    xlink_actuate_attribute = item['xlink_actuate_attribute']\n",
    "    xlink_show_attribute = item['xlink_show_attribute']\n",
    "\n",
    "    file_version = {'file_uri':file_uri,'publish':publish,'xlink_actuate_attribute':xlink_actuate_attribute,'xlink_show_attribute':xlink_show_attribute}\n",
    "\n",
    "    #retrieve the full archival object record via API\n",
    "    ao_record = requests.get(HOST + '/repositories/2/archival_objects/' + ao_id, headers=headers)\n",
    "    if ao_record.status_code == 404:\n",
    "        raise Exception('This archival object couldn\\'t be retrieved with the api. Something may be wrong with the URL?: ' + item['archival_object'])\n",
    "    else:\n",
    "        ao_record = ao_record.json()\n",
    "        \n",
    "    #Logic for picking title from AO or if overriding with CSV title\n",
    "    if item['new_title'] == \"\":\n",
    "        title = ao_record['title']\n",
    "    else:\n",
    "        title = item['new_title']\n",
    "\n",
    "\n",
    "    #clear variables\n",
    "    existing_do_record = None\n",
    "    skipitem = False\n",
    "\n",
    "    if 'instances' in ao_record: #if the archival object already has any instances\n",
    "        digital_object_IDs = [] #blank list to hold existing digital object IDs\n",
    "        for instance in ao_record['instances']: #for each instance:\n",
    "            if instance['instance_type'] != 'digital_object': #skip it if it isn't a digital object\n",
    "                continue #skip this instance and move onto the next one\n",
    "            else: #if the instance is a Digital Object:\n",
    "                do_id = instance['digital_object']['ref'] #get its ID\n",
    "                #print('Found existing Digital Object record: ' + do_id)\n",
    "                existing_do_record = requests.get(HOST + do_id, headers=headers) #request the full record from the API\n",
    "                if existing_do_record.status_code == 200: #if it retrieves the DO record successfully:\n",
    "                    existing_do_record = existing_do_record.json()\n",
    "                    #add the digital object to list of ids for this archival object\n",
    "                    digital_object_IDs.append(existing_do_record['digital_object_id'])\n",
    "                    #check if link is already in DO\n",
    "                    for existing_file_version in existing_do_record['file_versions']:\n",
    "                        if existing_file_version['file_uri'] == file_uri:\n",
    "                            print('This Digital Object already has your link: '+do_id+' Skipping this row . . . ')\n",
    "                            skipitem = True\n",
    "                else: #if it can't retrieve successfully:\n",
    "                    print('There is a Digital Object linked to this archival object, but could not retrieve it: ' + do_id)\n",
    "                    print(existing_do_record)\n",
    "                    raise Exception('Stopping script because there was an error retrieving an existing Digital Object linked to this archival object: ' + do_id)\n",
    "    if skipitem: #If, in the last loop through instances, the script found your link,\n",
    "        #then skip this item and don't make any edits\n",
    "        print('Skipped: your link was already there!\\n')\n",
    "    else:\n",
    "        #Create a new Digital Object\n",
    "        #print('Archival object doesn\\'t have this link. Creating a new Digital Object and linking it . . .')\n",
    "        new_digital_object = {}\n",
    "\n",
    "        new_digital_object['file_versions'] = []\n",
    "        new_digital_object['file_versions'].append(file_version)\n",
    "        new_digital_object['jsonmodel_type'] = ['digital_object']\n",
    "\n",
    "        #generate a digital object ID based on the first file_id\n",
    "        do_id = re.search('.+/(.+?)(\\..{3,4})?\\*?$', file_uri).group(1)\n",
    "        if any(x in file_uri for x in preservation_URLS_have):#if the link is to the preservation server\n",
    "            new_digital_object['title'] = 'Preservation copy: ' + title\n",
    "            do_id_preCheck = do_id + '_presCopy_01' #make the digital object ID have _presCopy_01 on the end\n",
    "            if any(x == do_id_preCheck for x in digital_object_IDs): #If that id is already taken by a DO attached to this item\n",
    "                do_id = do_id_preCheck[:-2] + id_generator()\n",
    "                print(' ***** WARNING *****  DIGITAL OBJECT ID taken:' + do_id_preCheck + '\\nFaux code was appended:' + do_id)\n",
    "            new_digital_object['digital_object_id'] = do_id\n",
    "        else:\n",
    "            new_digital_object['title'] = 'Online copy: ' + title\n",
    "            do_id_preCheck = do_id + '_onlineCopy_01' #make the digital object ID have _presCopy_01 on the end\n",
    "            if any(x == do_id_preCheck for x in digital_object_IDs): #If that id is already taken by a DO attached to this item\n",
    "                do_id = do_id_preCheck[:-2] + id_generator()\n",
    "                print('WARNING: DIGITAL OBJECT ID taken:' + do_id_preCheck + '\\nFaux code was appended:' + do_id)\n",
    "            new_digital_object['digital_object_id'] = do_id\n",
    "\n",
    "        new_do_record_post = json.dumps(new_digital_object)\n",
    "        new_digital_object_result = requests.post(HOST + '/repositories/2/digital_objects', headers=headers, data=new_do_record_post).json()\n",
    "        print(new_digital_object_result)\n",
    "        try:\n",
    "            if new_digital_object_result['error']['digital_object_id'][0] == 'Must be unique':\n",
    "                MustbeUnique_ErrorMessage = True\n",
    "        except:\n",
    "            MustbeUnique_ErrorMessage = None\n",
    "        if MustbeUnique_ErrorMessage:\n",
    "            do_id_try_again = do_id_preCheck[:-2] + id_generator()\n",
    "            new_digital_object['digital_object_id'] = do_id_try_again\n",
    "            print('The digital object id was not unique: ' + do_id +' \\nTrying again with digital object id: ' + new_digital_object['digital_object_id'])\n",
    "            new_do_try_again_post = json.dumps(new_digital_object)\n",
    "            new_digital_object_result = requests.post(HOST + '/repositories/2/digital_objects', headers=headers, data=new_do_try_again_post).json()\n",
    "            print(new_digital_object_result)\n",
    "        do_id_uri = str(new_digital_object_result['id'])\n",
    "        result_status = new_digital_object_result['status']\n",
    "        print('Result: ' + result_status)\n",
    "        print('New Digital Object: ' + str(new_digital_object_result['uri']))\n",
    "        #print('Linking Archival Object to Digital Object . . .')\n",
    "        #update AO to link to DO\n",
    "        add_to_ao = {'digital_object':{'ref': '/repositories/2/digital_objects/' + do_id_uri},'instance_type': 'digital_object'}\n",
    "        ao_record['instances'].append(add_to_ao)\n",
    "        ao_record_update = json.dumps(ao_record)\n",
    "        archival_object_update = requests.post(HOST + '/repositories/2/archival_objects/' + ao_id, headers=headers, data=ao_record_update).json()\n",
    "        print('Linking archival object. Result: ' + str(archival_object_update['status']))\n",
    "\n",
    "    print('')\n",
    "\n",
    "print('Done!')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
